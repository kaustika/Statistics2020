\documentclass[../body.tex]{subfiles}
\begin{document}
	Оценим, какие коэффициенты, полученные каким методом лучше аппроксимируют модельную зависимость: для МНК и МНМ для выборки с возмущениями и без них посчитаем сумму по всем $x \in [-1.8, 2]$, взятым с шагом $0.2$: $$Distance_{ls(lm)} = \sum{(y_{model} - y_{ls(lm)})^2}.$$
	$$y_{model} = 2 + 2 \cdot x$$
	$$y_{ls} = \hat{a}_{ls} + \hat{b}_{ls} \cdot x$$
	$$y_{ls} = \hat{a}_{lm} + \hat{b}_{lm} \cdot x$$
	Для данных выборок получаем:
	\begin{itemize}
		 \item Выборка без возмущений: $$Distance_{ls} < Distance_{lm}$$ $$0.563  <  1.637$$
		 Критерий наименьших квадратов точнее оценивает коэффициенты линейной регрессии на выборке без возмущений. 
		 \item Выборка без возмущений: $$Distance_{lm} < Distance_{ls}$$ $$1.393  <  43.805$$
		 Для выборки с возмущениями результат получается точнее при оценке критерием наименьших модулей.
	\end{itemize}
	Таким образом, критерий наименьших модулей устойчив к редким выбросам, в отличие от критерия наименьших квадратов, что соответствует ожиданиям, ведь он обладает робастными свойствами.
\end{document}